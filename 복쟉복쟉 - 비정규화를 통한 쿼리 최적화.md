---
tags:
  - problem-solving
---

# 문제 상황
복쟉복쟉 운영 DB에 혼잡도 데이터가 계속해서 쌓이면서 60만개가 넘어가던 상황.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/fe5901dd-0a5b-4523-95ba-894cad6cfbb2/4856269e-eaa3-47e0-a0c8-b574bc78c8e1/Untitled.png)

앱을 켜보니, 응답이 5초 이상 걸리고 있었다.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/fe5901dd-0a5b-4523-95ba-894cad6cfbb2/adaaeb4d-e906-459c-963f-5418a45479d8/Untitled.png)

나중에는 응답 시간이 너무 길어져서 에러가 났다.

스프링의 디폴트 **read timeout** 시간은 5초인데, 이를 초과한 것.

![1000006019.jpg](https://prod-files-secure.s3.us-west-2.amazonaws.com/fe5901dd-0a5b-4523-95ba-894cad6cfbb2/982b022c-830c-46bc-af3b-67731406d84d/1000006019.jpg)

read timeout이 발생한 것.

[https://alden-kang.tistory.com/20](https://alden-kang.tistory.com/20)

이렇게 오래 걸리기 시작하면 끝이 없겠다고 생각했다.

매일 몇만개씩 쌓여가고 있기 때문에 가면 갈수록 길어지고 있었다.

# 원인 분석

# 해결 과정
[[비정규화]]


## 💡 해결 방법 고민

❗ORDER BY DESC

order by를 하면 집계 필요 없이 모두 가져올 수 있게 된다.

문제점 : 그룹 짓지를 못하기 때문에 적재 서버 상황에 따라 개수가 안 맞아 엉뚱한 혼잡도들을 가져오게 됨

```sql
select
    c.location_id, observed_at
from
    congestion c
order by
    c.observed_at desc
limit 109;
```

ORDER BY를 사용하면 내부적으로 INDEX를 만들어 처리하는듯하다.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/fe5901dd-0a5b-4523-95ba-894cad6cfbb2/4283900a-0848-4948-a986-5c308c1e5370/Untitled.png)

원래는… 도움도 안 되는 FK (location_id)를 인덱스로 사용중이다.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/fe5901dd-0a5b-4523-95ba-894cad6cfbb2/1ef60bbe-7be8-49e2-a866-5bf512cfb46b/Untitled.png)

`Backward index scan` 이란게 중요해보인다.

## EXPLAIN

- 쿼리문
    
    ```sql
    EXPLAIN select
        l1_0.location_id,
        l1_0.api_id,
        c1_0.location_id,
        c1_0.congestion_id,
        c1_0.congestion_level,
        c1_0.created_at,
        c1_0.observed_at,
        c1_0.updated_at,
        l1_0.created_at,
        l2_0.location_category_id,
        l2_0.icon_image_url,
        l2_0.name,
        l1_0.name,
        l1_0.updated_at
    from
        location l1_0
            left join
        congestion c1_0
        on l1_0.location_id=c1_0.location_id
            left join
        location_category l2_0
        on l2_0.location_category_id=l1_0.location_category_id
            left join
        location_bookmark l3_0
        on l1_0.location_id=l3_0.location_id
    where
            (
             c1_0.location_id,c1_0.observed_at
                ) in(select
                         c2_0.location_id,max(c2_0.observed_at)
                     from
                         congestion c2_0
                     group by
                         c2_0.location_id
                     )
    order by
        null asc,
        l1_0.location_id asc;
    ```
    

|id|select\_type|table|partitions|type|possible\_keys|key|key\_len|ref|rows|filtered|Extra|
|---|---|---|---|---|---|---|---|---|---|---|---|
|1|PRIMARY|l1_0|null|index|PRIMARY|PRIMARY|8|null|112|100|null|
|1|PRIMARY|l2_0|null|eq\_ref|PRIMARY|PRIMARY|8|awsbuzzing.l1\_0.location\_category\_id|1|100|null|
|1|PRIMARY|l3_0|null|ref|FKcdr7befydtbo9k9miyf5rbxwd|FKcdr7befydtbo9k9miyf5rbxwd|8|awsbuzzing.l1\_0.location\_id|1|100|Using index|
|1|PRIMARY|c1_0|null|ref|FK2urj33m34b0gqk73cqhrna200|FK2urj33m34b0gqk73cqhrna200|8|awsbuzzing.l1\_0.location\_id|4469|100|Using where|
|2|SUBQUERY|c2_0|null|index|FK2urj33m34b0gqk73cqhrna200|FK2urj33m34b0gqk73cqhrna200|8|null|500571|100|null|

현재 FK (location_id)만이 사용되고 있다.

# INDEX 적용

## INDEX 초기

### USE INDEX : MAX 부분 인덱스 적용

❓인덱스 만들었는데 왜 사용이 안 되지? 그래서 일단 SQL문상에서는 USE INDEX로 지정해버렸다.

인덱스를 적용했더니 **3s 100 ms → 390 ms**

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/fe5901dd-0a5b-4523-95ba-894cad6cfbb2/ac23f000-98ce-45d5-b998-13f5336e1888/Untitled.png)

인덱스를 사용했더니… **약 8배 성능 개선**

```sql
### 인덱스 observed_at : 390ms
EXPLAIN select
            max(c.observed_at)
        from
            congestion c
                use index (congestion_observed_at_index)
        group by
            c.location_id;
```

복합 인덱스를 사용했더니 아주 조금 더 빨라졌다. 약 **8.2배** (표본이 적어서 오차가 있음)

```sql
### 복합 인덱스 observed_at, location_id : 375ms
EXPLAIN select
            max(c.observed_at)
        from
            congestion c
        use index (congestion_observed_at_location_id_index)
        group by
            c.location_id;
```

### 전체 적용

6s → 1s 100ms

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/fe5901dd-0a5b-4523-95ba-894cad6cfbb2/e8c5c5f0-9552-4d11-8058-f49413792f84/Untitled.png)

EXPLAIN 결과 :

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/fe5901dd-0a5b-4523-95ba-894cad6cfbb2/72bf95c4-ef2d-4ee2-9289-5eaec4ac93eb/Untitled.png)

|id|select\_type|table|partitions|type|possible\_keys|key|key\_len|ref|rows|filtered|Extra|
|---|---|---|---|---|---|---|---|---|---|---|---|
|1|PRIMARY|l1\_0|null|ALL|null|null|null|null|112|100|Using temporary; Using filesort|
|1|PRIMARY|c1\_0|null|ALL|null|null|null|null|607813|100|Using where; Using join buffer \(hash join\)|
|1|PRIMARY|l2\_0|null|eq\_ref|PRIMARY|PRIMARY|8|awsbuzzing.l1\_0.location\_category\_id|1|100|null|
|1|PRIMARY|l3\_0|null|ref|FKcdr7befydtbo9k9miyf5rbxwd|FKcdr7befydtbo9k9miyf5rbxwd|8|awsbuzzing.l1\_0.location\_id|1|100|Using index|
|2|SUBQUERY|c2\_0|null|index|congestion\_observed\_at\_location\_id\_index|congestion_observed_at_location_id_index|17|null|607813|100|Using index; Using temporary|

## 커버링 인덱스?

[커버링 인덱스](https://tecoble.techcourse.co.kr/post/2021-10-12-covering-index/)

**Using index for group-by 가 나와야 한다**

❗혼잡도 가져오는게 절반이다.

```sql
select
    c2_0.location_id,max(c2_0.observed_at)
from
    congestion c2_0
group by
    c2_0.location_id
```

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/fe5901dd-0a5b-4523-95ba-894cad6cfbb2/1d1a11ff-acba-42b3-a062-f7013708895d/Untitled.png)

## DATE TIME 형식을 변경?

[MySQL에서 DATETIME 형식 데이터 고속 검색 방법](https://devhood.tistory.com/249)

mysql의 UNIX_TIMESTAMP 이란게 있다.

INT형으로 저장하기 때문에, 일반적인 DATE_TIME보다 3~4배 빠르다고 한다

## 이제 Spring에 적용해보자.

❗그동안의 GROUP BY + 인덱싱되지 않은 컬럼의 문제점

[[Querydsl] 성능개선 - 3편 ( group by, 커버링 인덱스, update )](https://jessyt.tistory.com/74)

> Mysql 사용 시 index가 걸려있지 않는 컬럼을 group by 할 경우 file sort가 발생합니다.

### ⚠️with-clause not allowed on fetched associations; use filters

찾아보니 FETCH JOIN과 ON을 같이 사용했을 때 생기는 에러라고 한다.

### ⚠️ 애꿎은 FK 인덱스만 지정되는 문제

새로 생성한 복합 인덱스가 key로 쓰여야 하는데, 선택된건 FK였다.

![Screenshot from 2023-09-21 23-32-04.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/fe5901dd-0a5b-4523-95ba-894cad6cfbb2/cbdb90da-a9ef-4da6-b5d3-12c96408bfb9/Screenshot_from_2023-09-21_23-32-04.png)

❓JPA 혹은 QueryDSL에서 직접 인덱스를 지정햅버리는 방법은 없나?

❓spring jpa index 과정 출력 보는 방법은 없나? 이거 답답하네

## 마지막 시도…!

마지막 튜닝…!

|id|select\_type|table|partitions|type|possible\_keys|key|key\_len|ref|rows|filtered|Extra|
|---|---|---|---|---|---|---|---|---|---|---|---|
|1|PRIMARY|l1\_0|null|index|null|PRIMARY|8|null|1|100|null|
|1|PRIMARY|c1\_0|null|ref|FK2urj33m34b0gqk73cqhrna200|FK2urj33m34b0gqk73cqhrna200|8|awsbuzzing.l1\_0.location\_id|5681|100|Using where|
|1|PRIMARY|l4\_0|null|eq\_ref|PRIMARY|PRIMARY|8|awsbuzzing.l1\_0.location\_category\_id|1|100|null|
|1|PRIMARY|l5\_0|null|ref|FKcdr7befydtbo9k9miyf5rbxwd|FKcdr7befydtbo9k9miyf5rbxwd|8|awsbuzzing.l1\_0.location\_id|1|100|Using index|
|2|SUBQUERY|c2\_0|null|range|FK2urj33m34b0gqk73cqhrna200,congestion\_observed\_at\_location\_id\_index|congestion\_observed\_at\_location\_id\_index|9|null|49256|100|Using where; Using index; Using temporary|

⚠️그런데,,, 혼잡도 정렬시

|id|select\_type|table|partitions|type|possible\_keys|key|key\_len|ref|rows|filtered|Extra|
|---|---|---|---|---|---|---|---|---|---|---|---|
|1|PRIMARY|l1\_0|null|ALL|null|null|null|null|112|100|Using temporary; Using filesort|
|1|PRIMARY|c1\_0|null|ref|FK2urj33m34b0gqk73cqhrna200|FK2urj33m34b0gqk73cqhrna200|8|awsbuzzing.l1\_0.location\_id|5680|100|Using where|
|1|PRIMARY|l4\_0|null|eq\_ref|PRIMARY|PRIMARY|8|awsbuzzing.l1\_0.location\_category\_id|1|100|null|
|1|PRIMARY|l5\_0|null|ref|FKcdr7befydtbo9k9miyf5rbxwd|FKcdr7befydtbo9k9miyf5rbxwd|8|awsbuzzing.l1\_0.location\_id|1|100|Using index|
|2|SUBQUERY|c2\_0|null|range|FK2urj33m34b0gqk73cqhrna200,congestion\_observed\_at\_location\_id\_index|congestion\_observed\_at\_location\_id\_index|9|null|48230|100|Using where; Using index; Using temporary|

# ⭐ 결국… 실시간 혼잡도 컬럼 추가

## 🥲Redis를 포기한 이유

처음 생각한 Redis 방법 : 로케이션별로 실시간 혼잡도 데이터 저장 (location_id - congestion_level)

💡 2주간의 혼잡도 데이터들을 레디스에 저장해버리는건 어떨까? 주간 통계까지만 내고 그 다음엔 쓸 필요 없으니까.

❗**문제는 조회**

> join 과 같은 복잡한 데이터베이스 쿼리를 수행해야 하는 경우 다른 대안을 고려해야 합니다.
> 
> Redis는 key-value 형태로 저장되기 때문에 key 를 통해서만 액세스할 수 있습니다.

단순히 실시간 congestion을 빨리 가져온다고 해도, 결국 location과 congestion.congestion_level은 너무 긴밀하게 연결되어있기 때문에 조회를 할 때 둘이 엮일 때가 많아 최종적으로 비효율적인 쿼리가 된다.

요구사항 정리

로케이션 이름에 대한 검색 (WHERE)

로케이션 카테고리 id WHERE

커서 페이징 : 로케이션 id WHERE

congestion_level 순으로 정렬

congestion_level 커서 : 정렬과 커서 페이징을 함께 사용할 때 고질적인 문제.

커스텀 커서를 사용하면 어떨까? 아… 그런데 레디스에서 가져오면 쓸 수 없다.

❗결국 “로케이션 리스트 조회 **API의 관점**”에서 로케이션과 실시간 혼잡도는 **한 테이블**으로 생각해야 한다. INLINE VIEW 서브 쿼리가 떠오른다.

❗JPA는 **인라인 뷰** (FROM 절) **서브쿼리**를 지원하지 않는다. 이거 하나 제대로 배운거다. ❓ **인라인 뷰로 한번 짜보자**. 그러면 해결이 되었을까?

💡 ORDER BY 에서 congestion_level 순으로 나온 location_id 로 고정하면 해결 가능할지도?

커서 페이징(WHERE location_id < ?)과 ORDER BY congestion을 조회하기 때문에

**레디스 전략 진행 순서**

1. 레디스에서 로케이션별 congestion 싹 다 가져오기 ⇒ `congestionList`
2. 혼잡도순 정렬 요청일 경우, `congestionList` 를 congestion_level 순 JAVA 정렬 → location_id 커서, congestion_level 커서, limit으로 자르기
3. `congestionList` 의 location_id을 이용해 IN 절 조회 쿼리 + FETCH JOIN location_category, location.bookmarkList ⇒ `List<Location>`
4. → ORDER BY 순서를 지정해야 함… IN 절은 순서를 무시!!
5. 이어 붙이기…! : iteration index 혹은 location_id 기반으로 둘을 이어 붙여야 함

🤔 location 테이블에 realtime_congestion_level이 있는게 맞나?

우선 **조회 성능**만 생각하면 있는게 100% 맞다. ❗스키마를 결정하는건 무엇인가? 결국 조회, 삽입, 생성, 수정 등 실질적인 필요에 의해 결정되어야 한다.

실시간으로 **1:1 매핑**되기 때문에 구조상으론 맞다고 생각.

궁금한건, congestion에 있어야 할 데이터가 location에 있어도 되느냐는 것. 비즈니스 로직에 따라 DB 모양새가 바뀌어도 되는건가 하는 것임.

## ✨컬럼 추가 및 데이터 적재시 UPDATE 쿼리 추가 : 6s → 105ms

[[데이터베이스] 정규화 vs. 비정규화(반정규화)](https://owlyr.tistory.com/20#113a77b2-e481-43f8-a1b3-b31f767e9803)

Location 테이블에 컬럼 추가 : **real_time_congestion_level** (INT)

UPDATE 연산보다 SELECT 연산이 많기 때문에 
→ **적재 서버쪽에서 매번 UPDATE**쳐주면 됨

→ **정렬**하기에 너무 좋음. 내쪽에선 커스텀 커서를 이용해봐도 될듯.

성능상으로도 레디스를 쓰는 것과 차이가 없거나 더 빠를 수도 있음.


## INDEX를